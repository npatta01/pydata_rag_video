{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8ee1755-0a53-44a7-8234-a86607ce88ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Notebook : Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6e2e95-4143-4dc5-977f-073232a5a3ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "158323bb-aedb-4b00-9508-9836b200161e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## About"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58966d46-7c0b-476d-9d38-5fec4fd79315",
   "metadata": {},
   "source": [
    "In this notebook, we will motivate RAG.\n",
    "\n",
    "We will see why we can't use Large Language Model directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8390f695-3912-42b9-a440-ece9654f528d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5721f4c7-a6b5-4336-a4c7-f7c32f4ab397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dee1b64e-5046-4ebe-92ce-5468d6064d53",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa969cfa-69f6-4e33-a230-055f8a63e1af",
   "metadata": {},
   "source": [
    "make colab setup similar to if running in another env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a911145b-a18f-4f56-882e-7a922fedeb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running in Google Colab\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "if [[ -n \"$COLAB_RELEASE_TAG\" ]]; then\n",
    "    echo \"Running in Google Colab... will copy files relatively\"\n",
    "    \n",
    "    \n",
    "    rm -rf pydata_rag_video\n",
    "    git clone https://github.com/npatta01/pydata_rag_video.git\n",
    "    \n",
    "    cp pydata_rag_video/notebooks/video_utils.py /content/\n",
    "    cp pydata_rag_video/env /content/\n",
    "    \n",
    "    cp -r pydata_rag_video/images/ /content/\n",
    "    cp -r pydata_rag_video/images/ ../\n",
    "\n",
    "    cp -r pydata_rag_video/* /content/\n",
    "\n",
    "else\n",
    "  echo \"Not running in Google Colab\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0986cb11-3f8e-4f36-a7de-d076a75e8eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f1ef385-c0d5-44b6-9d93-5226d1d57d98",
   "metadata": {},
   "source": [
    "install pip dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63ce6151-9a88-4fbe-b15a-6b50df4ccbaa",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running in Google Colab\n",
      "Collecting git+https://github.com/openai/CLIP.git (from -r ../requirements.txt (line 14))\n",
      "  Cloning https://github.com/openai/CLIP.git to /var/tmp/pip-req-build-nptgmuzr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /var/tmp/pip-req-build-nptgmuzr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: python-dotenv==1.0.1 in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 2)) (1.0.1)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-gemini==0.3.* in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 3)) (0.3.1)\n",
      "Requirement already satisfied: llama-index-vector-stores-qdrant==0.3.* in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 4)) (0.3.2)\n",
      "Requirement already satisfied: llama-index-embeddings-gemini==0.2.* in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 5)) (0.2.1)\n",
      "Requirement already satisfied: huggingface_hub==0.26.2 in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 6)) (0.26.2)\n",
      "Requirement already satisfied: moviepy==1.0.* in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 7)) (1.0.3)\n",
      "Requirement already satisfied: pytubefix==8.2.* in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 8)) (8.2.0)\n",
      "Requirement already satisfied: SpeechRecognition==3.11.* in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 9)) (3.11.0)\n",
      "Requirement already satisfied: llama-index-vector-stores-lancedb==0.2.* in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 10)) (0.2.4)\n",
      "Requirement already satisfied: llama-index-embeddings-clip==0.2.* in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 11)) (0.2.0)\n",
      "Requirement already satisfied: rich==13.9.* in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 12)) (13.9.2)\n",
      "Requirement already satisfied: youtube_transcript_api==0.6.* in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 13)) (0.6.2)\n",
      "Requirement already satisfied: llama_index.embeddings.openai==0.2.* in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 15)) (0.2.5)\n",
      "Requirement already satisfied: llama_index.llms.openai==0.2.* in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 16)) (0.2.15)\n",
      "Requirement already satisfied: llama_index.multi_modal_llms.openai==0.2.* in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 17)) (0.2.2)\n",
      "Requirement already satisfied: llama-index-readers-file==0.2.* in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 18)) (0.2.2)\n",
      "Requirement already satisfied: llama-hub-youtube-transcript==0.0.* in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 19)) (0.0.1)\n",
      "Requirement already satisfied: llama-index-readers-youtube-transcript==0.2.* in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 20)) (0.2.0)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (0.11.19)\n",
      "Requirement already satisfied: llama-index-llms-gemini<0.4.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (0.3.7)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.2.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (10.4.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.60.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-vector-stores-qdrant==0.3.*->-r ../requirements.txt (line 4)) (1.67.1)\n",
      "Requirement already satisfied: qdrant-client>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-vector-stores-qdrant==0.3.*->-r ../requirements.txt (line 4)) (1.12.1)\n",
      "Requirement already satisfied: google-generativeai<0.6.0,>=0.5.2 in /opt/conda/lib/python3.10/site-packages (from llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (0.5.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub==0.26.2->-r ../requirements.txt (line 6)) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub==0.26.2->-r ../requirements.txt (line 6)) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub==0.26.2->-r ../requirements.txt (line 6)) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub==0.26.2->-r ../requirements.txt (line 6)) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub==0.26.2->-r ../requirements.txt (line 6)) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub==0.26.2->-r ../requirements.txt (line 6)) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub==0.26.2->-r ../requirements.txt (line 6)) (4.12.2)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in /opt/conda/lib/python3.10/site-packages (from moviepy==1.0.*->-r ../requirements.txt (line 7)) (4.4.2)\n",
      "Requirement already satisfied: proglog<=1.0.0 in /opt/conda/lib/python3.10/site-packages (from moviepy==1.0.*->-r ../requirements.txt (line 7)) (0.1.10)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from moviepy==1.0.*->-r ../requirements.txt (line 7)) (1.26.4)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /opt/conda/lib/python3.10/site-packages (from moviepy==1.0.*->-r ../requirements.txt (line 7)) (2.35.1)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from moviepy==1.0.*->-r ../requirements.txt (line 7)) (0.5.1)\n",
      "Requirement already satisfied: lancedb>=0.13.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-vector-stores-lancedb==0.2.*->-r ../requirements.txt (line 10)) (0.15.0)\n",
      "Requirement already satisfied: tantivy in /opt/conda/lib/python3.10/site-packages (from llama-index-vector-stores-lancedb==0.2.*->-r ../requirements.txt (line 10)) (0.22.0)\n",
      "Requirement already satisfied: ftfy<7.0.0,>=6.1.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (6.3.1)\n",
      "Requirement already satisfied: torch<3.0.0,>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (2.2.2)\n",
      "Requirement already satisfied: torchvision<0.18.0,>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (0.17.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich==13.9.*->-r ../requirements.txt (line 12)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich==13.9.*->-r ../requirements.txt (line 12)) (2.18.0)\n",
      "Requirement already satisfied: openai>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from llama_index.embeddings.openai==0.2.*->-r ../requirements.txt (line 15)) (1.52.0)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-readers-file==0.2.*->-r ../requirements.txt (line 18)) (4.12.3)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-readers-file==0.2.*->-r ../requirements.txt (line 18)) (4.3.1)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /opt/conda/lib/python3.10/site-packages (from llama-index-readers-file==0.2.*->-r ../requirements.txt (line 18)) (0.0.26)\n",
      "Requirement already satisfied: requests-html in /opt/conda/lib/python3.10/site-packages (from llama-hub-youtube-transcript==0.0.*->-r ../requirements.txt (line 19)) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->-r ../requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->-r ../requirements.txt (line 1)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->-r ../requirements.txt (line 1)) (2024.2)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from clip==1.0->-r ../requirements.txt (line 14)) (2024.9.11)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file==0.2.*->-r ../requirements.txt (line 18)) (2.6)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from ftfy<7.0.0,>=6.1.3->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (0.2.13)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.4 in /opt/conda/lib/python3.10/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (0.6.4)\n",
      "Requirement already satisfied: google-api-core in /opt/conda/lib/python3.10/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (1.34.1)\n",
      "Requirement already satisfied: google-api-python-client in /opt/conda/lib/python3.10/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (1.8.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (2.35.0)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (3.20.3)\n",
      "Requirement already satisfied: pydantic in /opt/conda/lib/python3.10/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (2.9.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (1.24.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from imageio-ffmpeg>=0.2.0->moviepy==1.0.*->-r ../requirements.txt (line 7)) (74.1.2)\n",
      "Requirement already satisfied: deprecation in /opt/conda/lib/python3.10/site-packages (from lancedb>=0.13.0->llama-index-vector-stores-lancedb==0.2.*->-r ../requirements.txt (line 10)) (2.1.0)\n",
      "Requirement already satisfied: pylance==0.19.1 in /opt/conda/lib/python3.10/site-packages (from lancedb>=0.13.0->llama-index-vector-stores-lancedb==0.2.*->-r ../requirements.txt (line 10)) (0.19.1)\n",
      "Requirement already satisfied: attrs>=21.3.0 in /opt/conda/lib/python3.10/site-packages (from lancedb>=0.13.0->llama-index-vector-stores-lancedb==0.2.*->-r ../requirements.txt (line 10)) (24.2.0)\n",
      "Requirement already satisfied: cachetools in /opt/conda/lib/python3.10/site-packages (from lancedb>=0.13.0->llama-index-vector-stores-lancedb==0.2.*->-r ../requirements.txt (line 10)) (5.5.0)\n",
      "Requirement already satisfied: overrides>=0.7 in /opt/conda/lib/python3.10/site-packages (from lancedb>=0.13.0->llama-index-vector-stores-lancedb==0.2.*->-r ../requirements.txt (line 10)) (7.7.0)\n",
      "Requirement already satisfied: pyarrow>=12 in /opt/conda/lib/python3.10/site-packages (from pylance==0.19.1->lancedb>=0.13.0->llama-index-vector-stores-lancedb==0.2.*->-r ../requirements.txt (line 10)) (15.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (3.10.10)\n",
      "Requirement already satisfied: dataclasses-json in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (1.0.8)\n",
      "Requirement already satisfied: httpx in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (3.4)\n",
      "Requirement already satisfied: nltk>3.8.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (3.9.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (0.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich==13.9.*->-r ../requirements.txt (line 12)) (0.1.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai>=1.1.0->llama_index.embeddings.openai==0.2.*->-r ../requirements.txt (line 15)) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai>=1.1.0->llama_index.embeddings.openai==0.2.*->-r ../requirements.txt (line 15)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from openai>=1.1.0->llama_index.embeddings.openai==0.2.*->-r ../requirements.txt (line 15)) (0.6.1)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai>=1.1.0->llama_index.embeddings.openai==0.2.*->-r ../requirements.txt (line 15)) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->-r ../requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: grpcio-tools>=1.41.0 in /opt/conda/lib/python3.10/site-packages (from qdrant-client>=1.7.1->llama-index-vector-stores-qdrant==0.3.*->-r ../requirements.txt (line 4)) (1.48.2)\n",
      "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /opt/conda/lib/python3.10/site-packages (from qdrant-client>=1.7.1->llama-index-vector-stores-qdrant==0.3.*->-r ../requirements.txt (line 4)) (2.10.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in /opt/conda/lib/python3.10/site-packages (from qdrant-client>=1.7.1->llama-index-vector-stores-qdrant==0.3.*->-r ../requirements.txt (line 4)) (1.26.20)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub==0.26.2->-r ../requirements.txt (line 6)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub==0.26.2->-r ../requirements.txt (line 6)) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub==0.26.2->-r ../requirements.txt (line 6)) (2024.8.30)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (1.13.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<3.0.0,>=2.1.2->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (12.4.127)\n",
      "Requirement already satisfied: pyquery in /opt/conda/lib/python3.10/site-packages (from requests-html->llama-hub-youtube-transcript==0.0.*->-r ../requirements.txt (line 19)) (2.0.1)\n",
      "Requirement already satisfied: fake-useragent in /opt/conda/lib/python3.10/site-packages (from requests-html->llama-hub-youtube-transcript==0.0.*->-r ../requirements.txt (line 19)) (1.5.1)\n",
      "Requirement already satisfied: parse in /opt/conda/lib/python3.10/site-packages (from requests-html->llama-hub-youtube-transcript==0.0.*->-r ../requirements.txt (line 19)) (1.20.2)\n",
      "Requirement already satisfied: bs4 in /opt/conda/lib/python3.10/site-packages (from requests-html->llama-hub-youtube-transcript==0.0.*->-r ../requirements.txt (line 19)) (0.0.2)\n",
      "Requirement already satisfied: w3lib in /opt/conda/lib/python3.10/site-packages (from requests-html->llama-hub-youtube-transcript==0.0.*->-r ../requirements.txt (line 19)) (2.2.1)\n",
      "Requirement already satisfied: pyppeteer>=0.0.14 in /opt/conda/lib/python3.10/site-packages (from requests-html->llama-hub-youtube-transcript==0.0.*->-r ../requirements.txt (line 19)) (2.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (1.14.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (4.0.3)\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama_index.embeddings.openai==0.2.*->-r ../requirements.txt (line 15)) (1.2.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (1.65.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (4.9)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (0.14.0)\n",
      "Requirement already satisfied: h2<5,>=3 in /opt/conda/lib/python3.10/site-packages (from httpx[http2]>=0.20.0->qdrant-client>=1.7.1->llama-index-vector-stores-qdrant==0.3.*->-r ../requirements.txt (line 4)) (4.1.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (1.4.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (2.23.4)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from pyppeteer>=0.0.14->requests-html->llama-hub-youtube-transcript==0.0.*->-r ../requirements.txt (line 19)) (1.4.4)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in /opt/conda/lib/python3.10/site-packages (from pyppeteer>=0.0.14->requests-html->llama-hub-youtube-transcript==0.0.*->-r ../requirements.txt (line 19)) (8.4.0)\n",
      "Requirement already satisfied: pyee<12.0.0,>=11.0.0 in /opt/conda/lib/python3.10/site-packages (from pyppeteer>=0.0.14->requests-html->llama-hub-youtube-transcript==0.0.*->-r ../requirements.txt (line 19)) (11.1.1)\n",
      "Requirement already satisfied: websockets<11.0,>=10.0 in /opt/conda/lib/python3.10/site-packages (from pyppeteer>=0.0.14->requests-html->llama-hub-youtube-transcript==0.0.*->-r ../requirements.txt (line 19)) (10.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (3.23.0)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (3.0.1)\n",
      "Requirement already satisfied: lxml>=2.1 in /opt/conda/lib/python3.10/site-packages (from pyquery->requests-html->llama-hub-youtube-transcript==0.0.*->-r ../requirements.txt (line 19)) (5.3.0)\n",
      "Requirement already satisfied: cssselect>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from pyquery->requests-html->llama-hub-youtube-transcript==0.0.*->-r ../requirements.txt (line 19)) (1.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<3.0.0,>=2.1.2->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (1.3.0)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (1.48.2)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in /opt/conda/lib/python3.10/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.7.1->llama-index-vector-stores-qdrant==0.3.*->-r ../requirements.txt (line 4)) (6.0.1)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in /opt/conda/lib/python3.10/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.7.1->llama-index-vector-stores-qdrant==0.3.*->-r ../requirements.txt (line 4)) (4.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2<1dev,>=0.9.2->google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (3.1.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html->llama-hub-youtube-transcript==0.0.*->-r ../requirements.txt (line 19)) (3.20.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (0.6.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "if [[ -n \"$COLAB_RELEASE_TAG\" ]]; then\n",
    "    echo \"Running in Google Colab\"\n",
    "    pip install -r requirements.txt\n",
    "\n",
    "else\n",
    "    echo \"Not running in Google Colab\"\n",
    "    pip install -r ../requirements.txt\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60a0ec8-6d7c-4e93-954a-fcf0b7cda086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25bea8f4-5664-462a-a783-e1aaf3d321bd",
   "metadata": {},
   "source": [
    "In case the youtube api, doesn't work this is backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8919ba53-279c-4857-927a-b7ec5e8eb8b1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running in Google Colab\n",
      "Collecting git+https://github.com/openai/CLIP.git (from -r ../requirements.txt (line 14))\n",
      "  Cloning https://github.com/openai/CLIP.git to /var/tmp/pip-req-build-u6ij54le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /var/tmp/pip-req-build-u6ij54le\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: python-dotenv==1.0.1 in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 2)) (1.0.1)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-gemini==0.3.* in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 3)) (0.3.1)\n",
      "Requirement already satisfied: llama-index-vector-stores-qdrant==0.3.* in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 4)) (0.3.2)\n",
      "Requirement already satisfied: llama-index-embeddings-gemini==0.2.* in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 5)) (0.2.1)\n",
      "Requirement already satisfied: huggingface_hub==0.26.2 in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 6)) (0.26.2)\n",
      "Requirement already satisfied: moviepy==1.0.* in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 7)) (1.0.3)\n",
      "Requirement already satisfied: pytubefix==8.2.* in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 8)) (8.2.0)\n",
      "Requirement already satisfied: SpeechRecognition==3.11.* in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 9)) (3.11.0)\n",
      "Requirement already satisfied: llama-index-vector-stores-lancedb==0.2.* in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 10)) (0.2.4)\n",
      "Requirement already satisfied: llama-index-embeddings-clip==0.2.* in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 11)) (0.2.0)\n",
      "Requirement already satisfied: rich==13.9.* in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 12)) (13.9.2)\n",
      "Requirement already satisfied: youtube_transcript_api==0.6.* in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 13)) (0.6.2)\n",
      "Requirement already satisfied: llama_index.embeddings.openai==0.2.* in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 15)) (0.2.5)\n",
      "Requirement already satisfied: llama_index.llms.openai==0.2.* in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 16)) (0.2.15)\n",
      "Requirement already satisfied: llama_index.multi_modal_llms.openai==0.2.* in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 17)) (0.2.2)\n",
      "Requirement already satisfied: llama-index-readers-file==0.2.* in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 18)) (0.2.2)\n",
      "Requirement already satisfied: llama-hub-youtube-transcript==0.0.* in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 19)) (0.0.1)\n",
      "Requirement already satisfied: llama-index-readers-youtube-transcript==0.2.* in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 20)) (0.2.0)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (0.11.19)\n",
      "Requirement already satisfied: llama-index-llms-gemini<0.4.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (0.3.7)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.2.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (10.4.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.60.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-vector-stores-qdrant==0.3.*->-r ../requirements.txt (line 4)) (1.67.1)\n",
      "Requirement already satisfied: qdrant-client>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-vector-stores-qdrant==0.3.*->-r ../requirements.txt (line 4)) (1.12.1)\n",
      "Requirement already satisfied: google-generativeai<0.6.0,>=0.5.2 in /opt/conda/lib/python3.10/site-packages (from llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (0.5.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub==0.26.2->-r ../requirements.txt (line 6)) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub==0.26.2->-r ../requirements.txt (line 6)) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub==0.26.2->-r ../requirements.txt (line 6)) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub==0.26.2->-r ../requirements.txt (line 6)) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub==0.26.2->-r ../requirements.txt (line 6)) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub==0.26.2->-r ../requirements.txt (line 6)) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub==0.26.2->-r ../requirements.txt (line 6)) (4.12.2)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in /opt/conda/lib/python3.10/site-packages (from moviepy==1.0.*->-r ../requirements.txt (line 7)) (4.4.2)\n",
      "Requirement already satisfied: proglog<=1.0.0 in /opt/conda/lib/python3.10/site-packages (from moviepy==1.0.*->-r ../requirements.txt (line 7)) (0.1.10)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from moviepy==1.0.*->-r ../requirements.txt (line 7)) (1.26.4)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /opt/conda/lib/python3.10/site-packages (from moviepy==1.0.*->-r ../requirements.txt (line 7)) (2.35.1)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from moviepy==1.0.*->-r ../requirements.txt (line 7)) (0.5.1)\n",
      "Requirement already satisfied: lancedb>=0.13.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-vector-stores-lancedb==0.2.*->-r ../requirements.txt (line 10)) (0.15.0)\n",
      "Requirement already satisfied: tantivy in /opt/conda/lib/python3.10/site-packages (from llama-index-vector-stores-lancedb==0.2.*->-r ../requirements.txt (line 10)) (0.22.0)\n",
      "Requirement already satisfied: ftfy<7.0.0,>=6.1.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (6.3.1)\n",
      "Requirement already satisfied: torch<3.0.0,>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (2.2.2)\n",
      "Requirement already satisfied: torchvision<0.18.0,>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (0.17.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich==13.9.*->-r ../requirements.txt (line 12)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich==13.9.*->-r ../requirements.txt (line 12)) (2.18.0)\n",
      "Requirement already satisfied: openai>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from llama_index.embeddings.openai==0.2.*->-r ../requirements.txt (line 15)) (1.52.0)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-readers-file==0.2.*->-r ../requirements.txt (line 18)) (4.12.3)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-readers-file==0.2.*->-r ../requirements.txt (line 18)) (4.3.1)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /opt/conda/lib/python3.10/site-packages (from llama-index-readers-file==0.2.*->-r ../requirements.txt (line 18)) (0.0.26)\n",
      "Requirement already satisfied: requests-html in /opt/conda/lib/python3.10/site-packages (from llama-hub-youtube-transcript==0.0.*->-r ../requirements.txt (line 19)) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->-r ../requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->-r ../requirements.txt (line 1)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->-r ../requirements.txt (line 1)) (2024.2)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from clip==1.0->-r ../requirements.txt (line 14)) (2024.9.11)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file==0.2.*->-r ../requirements.txt (line 18)) (2.6)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from ftfy<7.0.0,>=6.1.3->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (0.2.13)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.4 in /opt/conda/lib/python3.10/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (0.6.4)\n",
      "Requirement already satisfied: google-api-core in /opt/conda/lib/python3.10/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (1.34.1)\n",
      "Requirement already satisfied: google-api-python-client in /opt/conda/lib/python3.10/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (1.8.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (2.35.0)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (3.20.3)\n",
      "Requirement already satisfied: pydantic in /opt/conda/lib/python3.10/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (2.9.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (1.24.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from imageio-ffmpeg>=0.2.0->moviepy==1.0.*->-r ../requirements.txt (line 7)) (74.1.2)\n",
      "Requirement already satisfied: deprecation in /opt/conda/lib/python3.10/site-packages (from lancedb>=0.13.0->llama-index-vector-stores-lancedb==0.2.*->-r ../requirements.txt (line 10)) (2.1.0)\n",
      "Requirement already satisfied: pylance==0.19.1 in /opt/conda/lib/python3.10/site-packages (from lancedb>=0.13.0->llama-index-vector-stores-lancedb==0.2.*->-r ../requirements.txt (line 10)) (0.19.1)\n",
      "Requirement already satisfied: attrs>=21.3.0 in /opt/conda/lib/python3.10/site-packages (from lancedb>=0.13.0->llama-index-vector-stores-lancedb==0.2.*->-r ../requirements.txt (line 10)) (24.2.0)\n",
      "Requirement already satisfied: cachetools in /opt/conda/lib/python3.10/site-packages (from lancedb>=0.13.0->llama-index-vector-stores-lancedb==0.2.*->-r ../requirements.txt (line 10)) (5.5.0)\n",
      "Requirement already satisfied: overrides>=0.7 in /opt/conda/lib/python3.10/site-packages (from lancedb>=0.13.0->llama-index-vector-stores-lancedb==0.2.*->-r ../requirements.txt (line 10)) (7.7.0)\n",
      "Requirement already satisfied: pyarrow>=12 in /opt/conda/lib/python3.10/site-packages (from pylance==0.19.1->lancedb>=0.13.0->llama-index-vector-stores-lancedb==0.2.*->-r ../requirements.txt (line 10)) (15.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (3.10.10)\n",
      "Requirement already satisfied: dataclasses-json in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (1.0.8)\n",
      "Requirement already satisfied: httpx in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (3.4)\n",
      "Requirement already satisfied: nltk>3.8.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (3.9.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (0.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich==13.9.*->-r ../requirements.txt (line 12)) (0.1.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai>=1.1.0->llama_index.embeddings.openai==0.2.*->-r ../requirements.txt (line 15)) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai>=1.1.0->llama_index.embeddings.openai==0.2.*->-r ../requirements.txt (line 15)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from openai>=1.1.0->llama_index.embeddings.openai==0.2.*->-r ../requirements.txt (line 15)) (0.6.1)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai>=1.1.0->llama_index.embeddings.openai==0.2.*->-r ../requirements.txt (line 15)) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->-r ../requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: grpcio-tools>=1.41.0 in /opt/conda/lib/python3.10/site-packages (from qdrant-client>=1.7.1->llama-index-vector-stores-qdrant==0.3.*->-r ../requirements.txt (line 4)) (1.48.2)\n",
      "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /opt/conda/lib/python3.10/site-packages (from qdrant-client>=1.7.1->llama-index-vector-stores-qdrant==0.3.*->-r ../requirements.txt (line 4)) (2.10.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in /opt/conda/lib/python3.10/site-packages (from qdrant-client>=1.7.1->llama-index-vector-stores-qdrant==0.3.*->-r ../requirements.txt (line 4)) (1.26.20)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub==0.26.2->-r ../requirements.txt (line 6)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub==0.26.2->-r ../requirements.txt (line 6)) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub==0.26.2->-r ../requirements.txt (line 6)) (2024.8.30)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (1.13.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<3.0.0,>=2.1.2->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (12.4.127)\n",
      "Requirement already satisfied: pyquery in /opt/conda/lib/python3.10/site-packages (from requests-html->llama-hub-youtube-transcript==0.0.*->-r ../requirements.txt (line 19)) (2.0.1)\n",
      "Requirement already satisfied: fake-useragent in /opt/conda/lib/python3.10/site-packages (from requests-html->llama-hub-youtube-transcript==0.0.*->-r ../requirements.txt (line 19)) (1.5.1)\n",
      "Requirement already satisfied: parse in /opt/conda/lib/python3.10/site-packages (from requests-html->llama-hub-youtube-transcript==0.0.*->-r ../requirements.txt (line 19)) (1.20.2)\n",
      "Requirement already satisfied: bs4 in /opt/conda/lib/python3.10/site-packages (from requests-html->llama-hub-youtube-transcript==0.0.*->-r ../requirements.txt (line 19)) (0.0.2)\n",
      "Requirement already satisfied: w3lib in /opt/conda/lib/python3.10/site-packages (from requests-html->llama-hub-youtube-transcript==0.0.*->-r ../requirements.txt (line 19)) (2.2.1)\n",
      "Requirement already satisfied: pyppeteer>=0.0.14 in /opt/conda/lib/python3.10/site-packages (from requests-html->llama-hub-youtube-transcript==0.0.*->-r ../requirements.txt (line 19)) (2.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (1.14.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (4.0.3)\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama_index.embeddings.openai==0.2.*->-r ../requirements.txt (line 15)) (1.2.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (1.65.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (4.9)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (0.14.0)\n",
      "Requirement already satisfied: h2<5,>=3 in /opt/conda/lib/python3.10/site-packages (from httpx[http2]>=0.20.0->qdrant-client>=1.7.1->llama-index-vector-stores-qdrant==0.3.*->-r ../requirements.txt (line 4)) (4.1.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (1.4.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (2.23.4)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from pyppeteer>=0.0.14->requests-html->llama-hub-youtube-transcript==0.0.*->-r ../requirements.txt (line 19)) (1.4.4)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in /opt/conda/lib/python3.10/site-packages (from pyppeteer>=0.0.14->requests-html->llama-hub-youtube-transcript==0.0.*->-r ../requirements.txt (line 19)) (8.4.0)\n",
      "Requirement already satisfied: pyee<12.0.0,>=11.0.0 in /opt/conda/lib/python3.10/site-packages (from pyppeteer>=0.0.14->requests-html->llama-hub-youtube-transcript==0.0.*->-r ../requirements.txt (line 19)) (11.1.1)\n",
      "Requirement already satisfied: websockets<11.0,>=10.0 in /opt/conda/lib/python3.10/site-packages (from pyppeteer>=0.0.14->requests-html->llama-hub-youtube-transcript==0.0.*->-r ../requirements.txt (line 19)) (10.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (3.23.0)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (3.0.1)\n",
      "Requirement already satisfied: lxml>=2.1 in /opt/conda/lib/python3.10/site-packages (from pyquery->requests-html->llama-hub-youtube-transcript==0.0.*->-r ../requirements.txt (line 19)) (5.3.0)\n",
      "Requirement already satisfied: cssselect>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from pyquery->requests-html->llama-hub-youtube-transcript==0.0.*->-r ../requirements.txt (line 19)) (1.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<3.0.0,>=2.1.2->llama-index-embeddings-clip==0.2.*->-r ../requirements.txt (line 11)) (1.3.0)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (1.48.2)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in /opt/conda/lib/python3.10/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.7.1->llama-index-vector-stores-qdrant==0.3.*->-r ../requirements.txt (line 4)) (6.0.1)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in /opt/conda/lib/python3.10/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.7.1->llama-index-vector-stores-qdrant==0.3.*->-r ../requirements.txt (line 4)) (4.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2<1dev,>=0.9.2->google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (3.1.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html->llama-hub-youtube-transcript==0.0.*->-r ../requirements.txt (line 19)) (3.20.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-gemini==0.2.*->-r ../requirements.txt (line 5)) (0.6.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-multi-modal-llms-gemini==0.3.*->-r ../requirements.txt (line 3)) (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "if [[ -n \"$COLAB_RELEASE_TAG\" ]]; then\n",
    "    wget https://github.com/npatta01/pydata_rag_video/releases/download/latest/data.zip\n",
    "    unzip data.zip\n",
    "    cp -r data ../\n",
    "\n",
    "else\n",
    "    echo \"Not running in Google Colab\"\n",
    "    pip install -r ../requirements.txt\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97005ad3-1050-4ccc-ab29-883eee5ac098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd9b4622-b5c8-489d-ac0f-9e6d5c33b2eb",
   "metadata": {},
   "source": [
    "u might need to restart the runtime after installing the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264962cd-1e21-4291-9602-95a447623019",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29837f8-333b-4f3e-81b7-54c818822f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9e28f6b-db18-4813-8461-ac40d9e9f9b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import rich\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c2923b9-096b-4cae-9803-ed0650684dba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "#logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202d1432-85fb-470c-bc1e-681ea8b4734a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "716887a0-3343-4c8b-8d68-4913f7338d3a",
   "metadata": {},
   "source": [
    "set openai api key in \"env\" file or set as env variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee293172-3244-49a5-be12-19d4b8efeaf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dotenv_path = \"../env\"\n",
    "if os.path.isfile(\"env\"):\n",
    "    dotenv_path = \"env\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00d6bf40-2098-4ee3-8263-a8faa21b203d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(dotenv_path=dotenv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7684ea08-ff39-41c8-8f8b-d6bedb8e5065",
   "metadata": {},
   "source": [
    "make sure the above command ran fine and returned true.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f271cad6-f91f-40bc-9d3c-a761ed3d9aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17344597-dc17-42de-9bd4-2e5bb1b705ec",
   "metadata": {},
   "source": [
    "## Setup Complete\n",
    "\n",
    "wait before going to next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00e5c38-7b54-4075-9a45-50b15dcd4f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef95dbf6-a569-49b4-8387-d4647636d2ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e5b53da-5894-45b7-9a45-416df30e83cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# uncomment below line if not using env file \n",
    "\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cf51dc-db80-4128-80b2-e4fee4c4d1bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97317c4-1a8d-4166-b38e-565529eaf35d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d46a1ab0-3f7a-463b-a4df-9ed339e5c33e",
   "metadata": {},
   "source": [
    "## OpenAI calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2b80c93-43f0-4481-af18-660456798282",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d5512a3-3894-4a48-b6c1-f1bad8f7fd4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo\",temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cefbe5d-227c-46a4-af69-b3cf6c539854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd2b145-5aad-4f5f-b12c-003aa9b06f07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6deb45fe-a52d-4322-b950-509326434510",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_role_message = \"You are helpful tutor that explains complex topics in accessible manner\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a1b227-53b8-4898-8ae0-867645f33cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "beba11b7-b35c-4f64-9b67-73405e9e6c6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### call without full context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84f03a7c-e6c4-47b8-883f-fa98adeba4ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content= system_role_message\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"What are LLMs\"),\n",
    "]\n",
    "resp = llm.chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f45c4d-43cd-4424-bafc-b2b2ea49e7f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b2b0eba-5c13-47a2-b645-f14d9a4802db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">LLMs stand for Master of Laws, which is a postgraduate academic degree typically pursued by individuals who have \n",
       "already completed a law degree <span style=\"font-weight: bold\">(</span>such as a JD or LLB<span style=\"font-weight: bold\">)</span>. LLM programs allow students to specialize in a particular \n",
       "area of law, such as international law, environmental law, or intellectual property law. These programs often \n",
       "involve advanced coursework, research, and sometimes a thesis or dissertation. LLMs can be a valuable credential \n",
       "for individuals seeking to deepen their knowledge in a specific legal field or pursue a career in academia or \n",
       "international law.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "LLMs stand for Master of Laws, which is a postgraduate academic degree typically pursued by individuals who have \n",
       "already completed a law degree \u001b[1m(\u001b[0msuch as a JD or LLB\u001b[1m)\u001b[0m. LLM programs allow students to specialize in a particular \n",
       "area of law, such as international law, environmental law, or intellectual property law. These programs often \n",
       "involve advanced coursework, research, and sometimes a thesis or dissertation. LLMs can be a valuable credential \n",
       "for individuals seeking to deepen their knowledge in a specific legal field or pursue a career in academia or \n",
       "international law.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rich.print(resp.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ee182f7-44b0-4bbc-be16-0de5e9bc8f85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">MessageRole.ASSISTANT:</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span><span style=\"font-weight: bold\">&gt;</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'LLMs stand for Master of Laws, which is a postgraduate academic degree typically pursued by </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">individuals who have already completed a law degree (such as a JD or LLB). LLM programs allow students to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">specialize in a particular area of law, such as international law, environmental law, or intellectual property law.</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">These programs often involve advanced coursework, research, and sometimes a thesis or dissertation. LLMs can be a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">valuable credential for individuals seeking to deepen their knowledge in a specific legal field or pursue a career </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in academia or international law.'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">raw</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletion</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-AQbXRKDmG74owKOFnRrvQvUOX2U1D'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'LLMs stand for Master of Laws, which is a postgraduate academic degree typically </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">pursued by individuals who have already completed a law degree (such as a JD or LLB). LLM programs allow students </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to specialize in a particular area of law, such as international law, environmental law, or intellectual property </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">law. These programs often involve advanced coursework, research, and sometimes a thesis or dissertation. LLMs can </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">be a valuable credential for individuals seeking to deepen their knowledge in a specific legal field or pursue a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">career in academia or international law.'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">refusal</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">audio</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "                <span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1730904189</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo-0125'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">service_tier</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">108</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">135</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionTokensDetails</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">audio_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">reasoning_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">accepted_prediction_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">rejected_prediction_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PromptTokensDetails</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">audio_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">cached_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">delta</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">108</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">135</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mmessage\u001b[0m=\u001b[1;35mChatMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mrole\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mMessageRole.ASSISTANT:\u001b[0m\u001b[39m \u001b[0m\u001b[32m'assistant'\u001b[0m\u001b[1m>\u001b[0m,\n",
       "        \u001b[33mcontent\u001b[0m=\u001b[32m'LLMs stand for Master of Laws, which is a postgraduate academic degree typically pursued by \u001b[0m\n",
       "\u001b[32mindividuals who have already completed a law degree \u001b[0m\u001b[32m(\u001b[0m\u001b[32msuch as a JD or LLB\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. LLM programs allow students to \u001b[0m\n",
       "\u001b[32mspecialize in a particular area of law, such as international law, environmental law, or intellectual property law.\u001b[0m\n",
       "\u001b[32mThese programs often involve advanced coursework, research, and sometimes a thesis or dissertation. LLMs can be a \u001b[0m\n",
       "\u001b[32mvaluable credential for individuals seeking to deepen their knowledge in a specific legal field or pursue a career \u001b[0m\n",
       "\u001b[32min academia or international law.'\u001b[0m,\n",
       "        \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mraw\u001b[0m=\u001b[1;35mChatCompletion\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-AQbXRKDmG74owKOFnRrvQvUOX2U1D'\u001b[0m,\n",
       "        \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "            \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mfinish_reason\u001b[0m=\u001b[32m'stop'\u001b[0m,\n",
       "                \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "                \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mmessage\u001b[0m=\u001b[1;35mChatCompletionMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mcontent\u001b[0m=\u001b[32m'LLMs stand for Master of Laws, which is a postgraduate academic degree typically \u001b[0m\n",
       "\u001b[32mpursued by individuals who have already completed a law degree \u001b[0m\u001b[32m(\u001b[0m\u001b[32msuch as a JD or LLB\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. LLM programs allow students \u001b[0m\n",
       "\u001b[32mto specialize in a particular area of law, such as international law, environmental law, or intellectual property \u001b[0m\n",
       "\u001b[32mlaw. These programs often involve advanced coursework, research, and sometimes a thesis or dissertation. LLMs can \u001b[0m\n",
       "\u001b[32mbe a valuable credential for individuals seeking to deepen their knowledge in a specific legal field or pursue a \u001b[0m\n",
       "\u001b[32mcareer in academia or international law.'\u001b[0m,\n",
       "                    \u001b[33mrefusal\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,\n",
       "                    \u001b[33maudio\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[33mcreated\u001b[0m=\u001b[1;36m1730904189\u001b[0m,\n",
       "        \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-3.5-turbo-0125'\u001b[0m,\n",
       "        \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,\n",
       "        \u001b[33mservice_tier\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33msystem_fingerprint\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33musage\u001b[0m=\u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mcompletion_tokens\u001b[0m=\u001b[1;36m108\u001b[0m,\n",
       "            \u001b[33mprompt_tokens\u001b[0m=\u001b[1;36m27\u001b[0m,\n",
       "            \u001b[33mtotal_tokens\u001b[0m=\u001b[1;36m135\u001b[0m,\n",
       "            \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[1;35mCompletionTokensDetails\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33maudio_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "                \u001b[33mreasoning_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "                \u001b[33maccepted_prediction_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "                \u001b[33mrejected_prediction_tokens\u001b[0m=\u001b[1;36m0\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[33mprompt_tokens_details\u001b[0m=\u001b[1;35mPromptTokensDetails\u001b[0m\u001b[1m(\u001b[0m\u001b[33maudio_tokens\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mcached_tokens\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mdelta\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'prompt_tokens'\u001b[0m: \u001b[1;36m27\u001b[0m, \u001b[32m'completion_tokens'\u001b[0m: \u001b[1;36m108\u001b[0m, \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m135\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rich.print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6315e78-198e-417e-a518-29d1cbc70108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0761f50-0c6d-4579-8cfa-ae2db2ca8cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cc0b304-585d-45df-a186-e6109b9ada67",
   "metadata": {
    "tags": []
   },
   "source": [
    "### call with full context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90592a7e-fe04-467c-96a8-31211729344f",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content= system_role_message\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"What are LLMs in machine learning\"),\n",
    "]\n",
    "resp = llm.chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88cd994a-3095-43d0-b8b1-4ba842789223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">LLMs in machine learning stand for Large Language Models. These are a type of artificial intelligence model that is\n",
       "trained on vast amounts of text data to understand and generate human language. LLMs have been used in various \n",
       "natural language processing tasks such as language translation, text generation, sentiment analysis, and more.\n",
       "\n",
       "One of the most well-known examples of LLMs is OpenAI's GPT <span style=\"font-weight: bold\">(</span>Generative Pre-trained Transformer<span style=\"font-weight: bold\">)</span> series, which \n",
       "includes models like GPT-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> and GPT-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. These models have achieved impressive results in generating coherent and \n",
       "contextually relevant text based on the input they receive.\n",
       "\n",
       "LLMs have the ability to understand and generate human-like text, making them valuable tools for a wide range of \n",
       "applications in language processing and understanding.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "LLMs in machine learning stand for Large Language Models. These are a type of artificial intelligence model that is\n",
       "trained on vast amounts of text data to understand and generate human language. LLMs have been used in various \n",
       "natural language processing tasks such as language translation, text generation, sentiment analysis, and more.\n",
       "\n",
       "One of the most well-known examples of LLMs is OpenAI's GPT \u001b[1m(\u001b[0mGenerative Pre-trained Transformer\u001b[1m)\u001b[0m series, which \n",
       "includes models like GPT-\u001b[1;36m2\u001b[0m and GPT-\u001b[1;36m3\u001b[0m. These models have achieved impressive results in generating coherent and \n",
       "contextually relevant text based on the input they receive.\n",
       "\n",
       "LLMs have the ability to understand and generate human-like text, making them valuable tools for a wide range of \n",
       "applications in language processing and understanding.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rich.print(resp.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9764b1-7631-4b6b-b40d-2520d1b15914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29bf1d1f-bbf9-4a55-81b6-1d721ceee5a0",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235edbb9-9426-4021-9ec7-1ac5c1c62f7b",
   "metadata": {},
   "source": [
    "For us, when we hear `LLMs` we think of machine learning. \n",
    "\n",
    "But the term used to was first used to refere to a graduate degree for lawyers.\n",
    "\n",
    "So providing relevant context to the LLM is important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03b4f8a-2277-40ef-a4d2-1aa3868a7054",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
