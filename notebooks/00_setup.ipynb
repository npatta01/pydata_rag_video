{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8ee1755-0a53-44a7-8234-a86607ce88ff",
   "metadata": {},
   "source": [
    "# Notebook : Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6e2e95-4143-4dc5-977f-073232a5a3ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "158323bb-aedb-4b00-9508-9836b200161e",
   "metadata": {},
   "source": [
    "# About"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58966d46-7c0b-476d-9d38-5fec4fd79315",
   "metadata": {},
   "source": [
    "In this notebook, we will motivate RAG.\n",
    "\n",
    "We will see why we can't use Large Language Model directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8390f695-3912-42b9-a440-ece9654f528d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5721f4c7-a6b5-4336-a4c7-f7c32f4ab397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dee1b64e-5046-4ebe-92ce-5468d6064d53",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264962cd-1e21-4291-9602-95a447623019",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29837f8-333b-4f3e-81b7-54c818822f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e28f6b-db18-4813-8461-ac40d9e9f9b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import rich\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2923b9-096b-4cae-9803-ed0650684dba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "#logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7651f72-7cf7-4f77-9d47-0b4f01bd9b0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#logging.basicConfig(level=logging.DEBUG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202d1432-85fb-470c-bc1e-681ea8b4734a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "716887a0-3343-4c8b-8d68-4913f7338d3a",
   "metadata": {},
   "source": [
    "set openai api key in \"env\" file or set as env variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5b53da-5894-45b7-9a45-416df30e83cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv(dotenv_path=\"../env\")\n",
    "\n",
    "# uncomment below line if not using env file \n",
    "\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cf51dc-db80-4128-80b2-e4fee4c4d1bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97317c4-1a8d-4166-b38e-565529eaf35d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d46a1ab0-3f7a-463b-a4df-9ed339e5c33e",
   "metadata": {},
   "source": [
    "# OpenAI calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b80c93-43f0-4481-af18-660456798282",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5512a3-3894-4a48-b6c1-f1bad8f7fd4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo\",temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cefbe5d-227c-46a4-af69-b3cf6c539854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd2b145-5aad-4f5f-b12c-003aa9b06f07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deb45fe-a52d-4322-b950-509326434510",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_role_message = \"You are helpful tutor that explains complex topics in accessible manner\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a1b227-53b8-4898-8ae0-867645f33cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "beba11b7-b35c-4f64-9b67-73405e9e6c6b",
   "metadata": {},
   "source": [
    "## call without full context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f03a7c-e6c4-47b8-883f-fa98adeba4ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content= system_role_message\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"What are LLMs\"),\n",
    "]\n",
    "resp = llm.chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f45c4d-43cd-4424-bafc-b2b2ea49e7f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2b0eba-5c13-47a2-b645-f14d9a4802db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rich.print(resp.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee182f7-44b0-4bbc-be16-0de5e9bc8f85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rich.print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6315e78-198e-417e-a518-29d1cbc70108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0761f50-0c6d-4579-8cfa-ae2db2ca8cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cc0b304-585d-45df-a186-e6109b9ada67",
   "metadata": {},
   "source": [
    "## call with full context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90592a7e-fe04-467c-96a8-31211729344f",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content= system_role_message\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"What are LLMs in machine learning\"),\n",
    "]\n",
    "resp = llm.chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cd994a-3095-43d0-b8b1-4ba842789223",
   "metadata": {},
   "outputs": [],
   "source": [
    "rich.print(resp.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9764b1-7631-4b6b-b40d-2520d1b15914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29bf1d1f-bbf9-4a55-81b6-1d721ceee5a0",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235edbb9-9426-4021-9ec7-1ac5c1c62f7b",
   "metadata": {},
   "source": [
    "For us, when we hear `LLMs` we think of machine learning. \n",
    "\n",
    "But the term used to was furst used to refere to a graduate degree for lawyers.\n",
    "\n",
    "So providing relevant context to the LLM is important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03b4f8a-2277-40ef-a4d2-1aa3868a7054",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
